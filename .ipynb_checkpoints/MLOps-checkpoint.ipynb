{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22540b8-2adc-4c05-bcaf-be36d8f0cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f744ec-48db-40df-801a-4a3d2fd9f21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   booking_id         hotel  is_canceled  lead_time  arrival_date_year  \\\n",
      "0           0  Resort Hotel            0        342               2015   \n",
      "\n",
      "  arrival_date_month  arrival_date_week_number  arrival_date_day_of_month  \\\n",
      "0               July                        27                          1   \n",
      "\n",
      "   stays_in_weekend_nights  stays_in_week_nights  ...  agent  \\\n",
      "0                        0                     0  ...    0.0   \n",
      "\n",
      "   days_in_waiting_list  customer_type  adr required_car_parking_spaces  \\\n",
      "0                     0      Transient  0.0                           0   \n",
      "\n",
      "  total_of_special_requests reservation_status  reservation_status_date  \\\n",
      "0                         0          Check-Out               01/07/2015   \n",
      "\n",
      "   arrival_date  booking_date  \n",
      "0    01/07/2015    24/07/2014  \n",
      "\n",
      "[1 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('hotel_bookings_train_data.csv', sep = \";\")\n",
    "\n",
    "print(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc22d06b-449d-41ea-8bdb-aab95216bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'booking_date' to datetime if it's not already.\n",
    "data['booking_date'] = pd.to_datetime(data['booking_date'], format='%d/%m/%Y')\n",
    "\n",
    "hotel_bookings = data[data['booking_date'] < '2017-08-01'] # Data before ingestion begins\n",
    "\n",
    "# Filter rows where 'booking_date' is August 1st, 2017.\n",
    "data_profiling_before = data[data['booking_date'] == '2017-08-01'] # First day of ingestion. This will need to be automated with an Airflow variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca5803b7-286d-4ab2-a397-eebf22dc0e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['booking_id', 'hotel', 'is_canceled', 'lead_time', 'arrival_date_year',\n",
       "       'arrival_date_month', 'arrival_date_week_number',\n",
       "       'arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
       "       'stays_in_week_nights', 'adults', 'children', 'babies', 'meal',\n",
       "       'country', 'market_segment', 'distribution_channel',\n",
       "       'is_repeated_guest', 'previous_cancellations',\n",
       "       'previous_bookings_not_canceled', 'reserved_room_type',\n",
       "       'assigned_room_type', 'booking_changes', 'deposit_type', 'agent',\n",
       "       'days_in_waiting_list', 'customer_type', 'adr',\n",
       "       'required_car_parking_spaces', 'total_of_special_requests',\n",
       "       'reservation_status', 'reservation_status_date', 'arrival_date',\n",
       "       'booking_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_profiling_before.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0cbdc3a-58b6-4bb4-80fe-9382218849f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['booking_id', 'hotel', 'is_canceled', 'lead_time', 'arrival_date_year',\n",
       "       'arrival_date_month', 'arrival_date_week_number',\n",
       "       'arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
       "       'stays_in_week_nights', 'adults', 'children', 'babies', 'meal',\n",
       "       'country', 'market_segment', 'distribution_channel',\n",
       "       'is_repeated_guest', 'previous_cancellations',\n",
       "       'previous_bookings_not_canceled', 'reserved_room_type',\n",
       "       'assigned_room_type', 'booking_changes', 'deposit_type', 'agent',\n",
       "       'days_in_waiting_list', 'customer_type', 'adr',\n",
       "       'required_car_parking_spaces', 'total_of_special_requests',\n",
       "       'reservation_status', 'reservation_status_date', 'arrival_date',\n",
       "       'booking_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_bookings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30e52102-fd0a-4ae3-9400-bec15c1563a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in meal: ['BB' 'FB' 'HB' 'SC' 'Undefined']\n",
      "Unique values in country: ['PRT' 'GBR' 'USA' 'ESP' 'IRL' 'FRA' 'ROU' 'NOR' 'OMN' 'ARG' 'POL' 'DEU'\n",
      " 'BEL' 'CHE' 'CN' 'GRC' 'ITA' 'NLD' 'DNK' 'RUS' 'SWE' 'AUS' 'EST' 'CZE'\n",
      " 'BRA' 'FIN' 'MOZ' 'BWA' 'LUX' 'SVN' 'ALB' 'IND' 'CHN' 'MEX' 'MAR' 'UKR'\n",
      " 'SMR' 'LVA' 'PRI' 'SRB' 'CHL' 'AUT' 'BLR' 'LTU' 'TUR' 'ZAF' 'AGO' 'ISR'\n",
      " 'CYM' 'ZMB' 'CPV' 'ZWE' 'DZA' 'KOR' 'CRI' 'HUN' 'ARE' 'TUN' 'JAM' 'HRV'\n",
      " 'HKG' 'IRN' 'GEO' 'AND' 'GIB' 'URY' 'JEY' 'CAF' 'CYP' 'COL' 'GGY' 'KWT'\n",
      " 'NGA' 'MDV' 'VEN' 'SVK' 'FJI' 'KAZ' 'PAK' 'IDN' 'LBN' 'PHL' 'SEN' 'SYC'\n",
      " 'AZE' 'BHR' 'NZL' 'THA' 'DOM' 'MKD' 'MYS' 'ARM' 'JPN' 'LKA' 'CUB' 'CMR'\n",
      " 'BIH' 'MUS' 'COM' 'SUR' 'UGA' 'BGR' 'CIV' 'JOR' 'SYR' 'SGP' 'BDI' 'SAU'\n",
      " 'VNM' 'PLW' 'QAT' 'EGY' 'PER' 'MLT' 'MWI' 'ECU' 'MDG' 'ISL' 'UZB' 'NPL'\n",
      " 'BHS' 'MAC' 'TGO' 'TWN' 'DJI' 'STP' 'KNA' 'ETH' 'IRQ' 'HND' 'RWA' 'KHM'\n",
      " 'MCO' 'BGD' 'IMN' 'TJK' 'NIC' 'BEN' 'VGB' 'TZA' 'GAB' 'GHA' 'TMP' 'GLP'\n",
      " 'KEN' 'LIE' 'GNB' 'MNE' 'UMI' 'MYT' 'FRO' 'MMR' 'PAN' 'BFA' 'LBY' 'MLI'\n",
      " 'NAM' 'BOL' 'PRY' 'BRB' 'ABW' 'AIA' 'SLV' 'DMA' 'PYF' 'GUY' 'LCA' 'ATA'\n",
      " 'GTM' 'ASM' 'MRT' 'NCL' 'KIR' 'SDN' 'ATF' 'SLE']\n",
      "Unique values in market_segment: ['Direct' 'Corporate' 'Online TA' 'Offline TA/TO' 'Complementary' 'Groups'\n",
      " 'Aviation']\n",
      "Unique values in distribution_channel: ['Direct' 'Corporate' 'TA/TO' 'Undefined' 'GDS']\n",
      "Unique values in is_repeated_guest: [0 1]\n",
      "Unique values in reserved_room_type: ['C' 'A' 'D' 'E' 'G' 'F' 'H' 'L' 'B']\n",
      "Unique values in assigned_room_type: ['C' 'A' 'D' 'E' 'G' 'F' 'I' 'B' 'H' 'L' 'K']\n",
      "Unique values in deposit_type: ['No Deposit' 'Refundable' 'Non Refund']\n",
      "Unique values in agent: [  0. 304. 240. 303.  15. 241.   8. 250. 115.   5. 175. 134. 156. 243.\n",
      " 242.   3. 105.  40. 147. 306. 184.  96.   2. 127.  95. 146.   9. 177.\n",
      "   6. 143. 244. 149. 167. 300. 171. 305.  67. 196. 152. 142. 261. 104.\n",
      "  36.  26.  29. 258. 110.  71. 181.  88. 251. 275.  69. 248. 208. 256.\n",
      " 314. 126. 281. 273. 253. 185. 330. 334. 328. 326. 321. 324. 313.  38.\n",
      " 155.  68. 335. 308. 332.  94. 348. 310. 339. 375.  66. 327. 387. 298.\n",
      "  91. 245. 385. 257. 393. 168. 405. 249. 315.  75. 128. 307.  11. 436.\n",
      "   1. 201. 183. 223. 368. 336. 291. 464. 411. 481.  10. 154. 468. 410.\n",
      " 390. 440. 495. 492. 493. 434.  57. 531. 420. 483. 526. 472. 429.  16.\n",
      "  34. 252. 270.  47. 114. 301. 193. 182. 135. 350. 195. 352. 355. 159.\n",
      " 139. 363. 384. 360. 331. 367.  64.  78. 406. 163. 414. 333. 427. 431.\n",
      " 430. 426. 438. 433. 418. 441. 282. 432.  72. 450. 180. 454. 455.  59.\n",
      " 451. 254. 358. 469. 165. 467. 510. 337. 476. 502. 527. 479. 508. 535.\n",
      " 302. 497. 187.  13.   7.  27.  14.  22.  17.  28.  42.  20.  19.  45.\n",
      "  37.  61.  39.  21.  24.  41.  50.  30.  54.  52.  12.  44.  31.  83.\n",
      "  32.  63.  60.  55.  56.  89.  87. 118.  86.  85. 210. 214. 129. 179.\n",
      " 138. 174. 170. 153.  93. 151. 119.  35. 173.  58.  53. 133.  79. 235.\n",
      " 192. 191. 236. 162. 215. 157. 287. 132. 234.  98.  77. 103. 107. 262.\n",
      " 220. 121. 205. 378.  23. 296. 290. 229.  33. 286. 276. 425. 484. 323.\n",
      " 403. 219. 394. 509. 423.   4.  70.  82.  81.  74.  92.  99.  90. 112.\n",
      " 117. 106. 111. 148. 158. 144. 211. 213. 216. 232. 150. 267. 227. 247.\n",
      " 278. 280. 285. 289. 269. 295. 265. 288. 122. 294. 325. 341. 344. 346.\n",
      " 359. 283. 364. 370. 371.  25. 141. 391. 397. 416. 404. 299. 197.  73.\n",
      " 354. 444. 408. 461. 388. 453. 459. 474. 475. 480. 449.]\n",
      "Unique values in customer_type: ['Transient' 'Contract' 'Transient-Party' 'Group']\n"
     ]
    }
   ],
   "source": [
    "cat_col = ['meal','country','market_segment','distribution_channel','is_repeated_guest','reserved_room_type','assigned_room_type','deposit_type','agent','customer_type',]\n",
    "\n",
    "for col in cat_col:\n",
    "    print(f\"Unique values in {col}: {data[col].unique()}\")\n",
    "    \n",
    "cat_col_eval = ['meal','market_segment','distribution_channel','is_repeated_guest','reserved_room_type','assigned_room_type','deposit_type','customer_type']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf1f29-ae92-4c2a-bf5e-543f51d44ac5",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4dcd14-5632-4d7e-b353-08308f7a3a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75487b5a-cf0b-4b4d-8542-8c0cce3b7f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Analysis\n",
      "hotel_bookings:\n",
      "Alert: hotel_booking. The correlation between stays_in_weekend_nights and stays_in_week_nights is 0.50\n",
      "data_profiling_before:\n",
      "Alert: data_profiling_before. The correlation between lead_time and adr is 0.57\n",
      "Alert: data_profiling_before. The correlation between children and adr is 0.52\n"
     ]
    }
   ],
   "source": [
    "print('Correlation Analysis')\n",
    "\n",
    "print('hotel_bookings:')\n",
    "correlation_matrix = hotel_bookings[num_cols].corr()\n",
    "# Iterate over the correlation matrix\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):  # i+1 to skip diagonal\n",
    "        if correlation_matrix.iloc[i, j] < -0.4 or correlation_matrix.iloc[i, j] > 0.4:\n",
    "            print(f\"Alert: hotel_booking. The correlation between {correlation_matrix.columns[i]} and {correlation_matrix.columns[j]} is {correlation_matrix.iloc[i, j]:.2f}\")\n",
    "\n",
    "print(\"data_profiling_before:\")\n",
    "correlation_matrix = data_profiling_before[num_cols].corr()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):  # i+1 to skip diagonal\n",
    "        if correlation_matrix.iloc[i, j] < -0.4 or correlation_matrix.iloc[i, j] > 0.4:\n",
    "            print(f\"Alert: data_profiling_before. The correlation between {correlation_matrix.columns[i]} and {correlation_matrix.columns[j]} is {correlation_matrix.iloc[i, j]:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ba17564-6f58-4886-b8a9-2c7b1f3f4dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null counts in each column:\n",
      "booking_id                        0\n",
      "hotel                             0\n",
      "is_canceled                       0\n",
      "lead_time                         0\n",
      "arrival_date_year                 0\n",
      "arrival_date_month                0\n",
      "arrival_date_week_number          0\n",
      "arrival_date_day_of_month         0\n",
      "stays_in_weekend_nights           0\n",
      "stays_in_week_nights              0\n",
      "adults                            0\n",
      "children                          0\n",
      "babies                            0\n",
      "meal                              0\n",
      "country                           0\n",
      "market_segment                    0\n",
      "distribution_channel              0\n",
      "is_repeated_guest                 0\n",
      "previous_cancellations            0\n",
      "previous_bookings_not_canceled    0\n",
      "reserved_room_type                0\n",
      "assigned_room_type                0\n",
      "booking_changes                   0\n",
      "deposit_type                      0\n",
      "agent                             0\n",
      "days_in_waiting_list              0\n",
      "customer_type                     0\n",
      "adr                               0\n",
      "required_car_parking_spaces       0\n",
      "total_of_special_requests         0\n",
      "reservation_status                0\n",
      "reservation_status_date           0\n",
      "arrival_date                      0\n",
      "booking_date                      0\n",
      "dtype: int64\n",
      "\n",
      "Count of categorical columns: 12\n",
      "Count of numerical columns: 11\n",
      "Count of binary columns: 3\n",
      "Check for outliers --> 4 x standard deviation \n",
      "Booking ID 26641 outlier values: {'previous_bookings_not_canceled': 1}\n",
      "Booking ID 32471 outlier values: {'stays_in_week_nights': 10}\n",
      "Booking ID 67370 outlier values: {'stays_in_week_nights': 10}\n",
      "Booking ID 104341 outlier values: {'babies': 1.0}\n",
      "Check for non-binary values in binary columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming data_profiling_before is your DataFrame\n",
    "\n",
    "# Count the number of nulls in each column\n",
    "null_counts = data_profiling_before.isnull().sum()\n",
    "print(\"Null counts in each column:\")\n",
    "print(null_counts)\n",
    "\n",
    "\n",
    "\n",
    "numerical_cols = ['lead_time','stays_in_weekend_nights','stays_in_week_nights', 'adults', 'children', 'babies','previous_cancellations','previous_bookings_not_canceled','days_in_waiting_list',  'adr','total_of_special_requests',]\n",
    "binary_cols = ['is_canceled','is_repeated_guest','required_car_parking_spaces',]\n",
    "categorical_cols = ['hotel','meal','country', 'market_segment', 'distribution_channel','reserved_room_type','assigned_room_type', 'booking_changes', 'deposit_type', 'agent','customer_type','reservation_status',]\n",
    "time_cols = ['booking_id','arrival_date_year', 'arrival_date_month', 'arrival_date_week_number','arrival_date_day_of_month','reservation_status_date', 'arrival_date', 'booking_date']\n",
    "        \n",
    "print(f\"\\nCount of categorical columns: {len(categorical_cols)}\")\n",
    "print(f\"Count of numerical columns: {len(numerical_cols)}\")\n",
    "print(f\"Count of binary columns: {len(binary_cols)}\")     \n",
    "\n",
    "# Define a function to detect outliers using IQR\n",
    "def detect_outliers_iqr(data):\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "    lower_bound = mean - 4 * std\n",
    "    upper_bound = mean + 4 * std\n",
    "    return data[(data < lower_bound) | (data > upper_bound)]\n",
    "\n",
    "# Initialize the DataFrame to store outliers\n",
    "outliers_df = pd.DataFrame()\n",
    "\n",
    "# Detect and store outliers for each numerical column\n",
    "for col in numerical_cols:\n",
    "    outliers = detect_outliers_iqr(data_profiling_before[col])\n",
    "    outliers_df[col] = data_profiling_before[col].isin(outliers)\n",
    "\n",
    "# Now, create a mask that indicates whether each row has at least one outlier\n",
    "outliers_mask = outliers_df.any(axis=1)\n",
    "\n",
    "print('Check for outliers --> 4 x standard deviation ')\n",
    "        \n",
    "for index, row in outliers_df.iterrows():\n",
    "    if row.any():  # Check if the row has any True values indicating outliers\n",
    "        # Retrieve the booking_id for the current row\n",
    "        booking_id = data_profiling_before.loc[index, 'booking_id']\n",
    "        \n",
    "        # Get the list of column names where this row is an outlier\n",
    "        outlier_columns = row[row].index.tolist()\n",
    "        \n",
    "        # Retrieve the values of the outlier columns for the current row\n",
    "        outlier_values = data_profiling_before.loc[index, outlier_columns].to_dict()\n",
    "        \n",
    "        #print(f\"Booking ID {booking_id} has outliers in columns: {outlier_columns}. Outlier values: {outlier_values}\")\n",
    "        print(f\"Booking ID {booking_id} outlier values: {outlier_values}\")\n",
    "\n",
    "        \n",
    "print('Check for non-binary values in binary columns')\n",
    "for col in binary_cols:\n",
    "    non_binary_rows = data_profiling_before[~data_profiling_before[col].isin([0, 1])]\n",
    "    if not non_binary_rows.empty:\n",
    "        for index, row in non_binary_rows.iterrows():\n",
    "            booking_id = row['booking_id']\n",
    "            print(f\"Non-binary alert for booking ID {booking_id} in column {col}: Value = {row[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "667f2539-027c-4755-ba50-638430b34238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First quartile (Q1): 0.0\n",
      "Second quartile (Q2) / Median: 0.0\n",
      "Third quartile (Q3): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate quartiles\n",
    "Q1 = data_profiling_before['children'].quantile(0.25)\n",
    "Q2 = data_profiling_before['children'].quantile(0.5)\n",
    "Q3 = data_profiling_before['children'].quantile(0.75)\n",
    "\n",
    "# Print quartiles\n",
    "print(f\"First quartile (Q1): {Q1}\")\n",
    "print(f\"Second quartile (Q2) / Median: {Q2}\")\n",
    "print(f\"Third quartile (Q3): {Q3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb04d3-d4fd-421b-9835-6a67cd166361",
   "metadata": {},
   "source": [
    "## Input Features Drift Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "088db49a-843c-40ff-87ea-b8b61f135772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data Exploration for Numerical Columns\n",
      "We only study features generated at booking time. For instance, we exclude number of days in waitlist.\n",
      "T-TEST AND K-S TEST\n",
      "T-TEST Alert! We found significant differences in the new data based on T-test!\n",
      "                          Feature  P-value (T-test)    Old Mean    New Mean  \\\n",
      "0                       lead_time      6.659678e-03  106.491758   93.705882   \n",
      "1                          adults      2.204078e-07    1.857458    2.064171   \n",
      "2                        children      2.894354e-03    0.101311    0.229947   \n",
      "3          previous_cancellations     1.118476e-270    0.090199    0.000000   \n",
      "4  previous_bookings_not_canceled      3.195051e-54    0.125742    0.005348   \n",
      "5                             adr      2.453943e-05  100.763441  116.156257   \n",
      "6       total_of_special_requests      1.171315e-06    0.564796    0.898396   \n",
      "\n",
      "   Percentage Change  \n",
      "0         -12.006446  \n",
      "1          11.128813  \n",
      "2         126.971426  \n",
      "3        -100.000000  \n",
      "4         -95.747162  \n",
      "5          15.276191  \n",
      "6          59.065476  \n",
      "K-S TEST Alert! We found significant differences in the new data based on K-S test!\n",
      "                     Feature  P-value (K-S test)\n",
      "0                  lead_time        7.793113e-05\n",
      "1                     adults        9.035560e-03\n",
      "2                        adr        2.738028e-08\n",
      "3  total_of_special_requests        1.662662e-05\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "print('New Data Exploration for Numerical Columns')\n",
    "\n",
    "print('We only study features generated at booking time. For instance, we exclude number of days in waitlist.')\n",
    "\n",
    "print('T-TEST AND K-S TEST')\n",
    "\n",
    "num_cols = [\n",
    "    'lead_time', 'stays_in_weekend_nights', 'stays_in_week_nights',\n",
    "    'adults', 'children', 'babies', 'previous_cancellations',\n",
    "    'previous_bookings_not_canceled', 'adr', 'total_of_special_requests'\n",
    "]\n",
    "\n",
    "# Initialize dictionaries to store the p-values for each test\n",
    "p_values_ttest = {}\n",
    "p_values_ks = {}\n",
    "\n",
    "# Dictionary to store means for each group and column\n",
    "means = {}\n",
    "\n",
    "p_value_threshold = 0.01\n",
    "\n",
    "for col in num_cols:\n",
    "    # Perform the T-test\n",
    "    t_stat, p_val_ttest = stats.ttest_ind(\n",
    "        hotel_bookings[col].dropna(),\n",
    "        data_profiling_before[col].dropna(),\n",
    "        equal_var=False\n",
    "    )\n",
    "    # Store the p-value from the T-test in the dictionary\n",
    "    p_values_ttest[col] = p_val_ttest\n",
    "    \n",
    "    # Perform the Kolmogorov-Smirnov test\n",
    "    ks_stat, p_val_ks = stats.ks_2samp(\n",
    "        hotel_bookings[col].dropna(),\n",
    "        data_profiling_before[col].dropna()\n",
    "    )\n",
    "    # Store the p-value from the K-S test in the dictionary\n",
    "    p_values_ks[col] = p_val_ks\n",
    "    \n",
    "    # Calculate and store the means\n",
    "    mean_hotel_bookings = hotel_bookings[col].mean()\n",
    "    mean_data_profiling_before = data_profiling_before[col].mean()\n",
    "    means[col] = (mean_hotel_bookings, mean_data_profiling_before)\n",
    "\n",
    "# Prepare data for DataFrame for T-test\n",
    "significant_data_ttest = [\n",
    "    (\n",
    "        col, \n",
    "        p_values_ttest[col], \n",
    "        means[col][0],  # Old Mean (hotel_bookings)\n",
    "        means[col][1],  # New Mean (data_profiling_before)\n",
    "        ((means[col][1] - means[col][0]) / means[col][0] * 100) if means[col][0] != 0 else 'Infinity' # Percentage Change\n",
    "    ) \n",
    "    for col in num_cols \n",
    "    if p_values_ttest[col] < p_value_threshold\n",
    "]\n",
    "\n",
    "# Convert to DataFrame with columns for p-value, old mean, new mean, and percentage change for T-test\n",
    "significant_cols_df_ttest = pd.DataFrame(\n",
    "    significant_data_ttest, \n",
    "    columns=['Feature', 'P-value (T-test)', 'Old Mean', 'New Mean', 'Percentage Change']\n",
    ")\n",
    "\n",
    "# Prepare data for DataFrame for K-S test\n",
    "significant_data_ks = [\n",
    "    (col, p_values_ks[col]) for col in num_cols if p_values_ks[col] < p_value_threshold\n",
    "]\n",
    "\n",
    "# Convert to DataFrame with columns for feature and p-value for K-S test\n",
    "significant_cols_df_ks = pd.DataFrame(\n",
    "    significant_data_ks, \n",
    "    columns=['Feature', 'P-value (K-S test)']\n",
    ")\n",
    "\n",
    "# Print results\n",
    "if not significant_cols_df_ttest.empty:\n",
    "    messagettest = 'T-TEST Alert! We found significant differences in the new data based on T-test!'\n",
    "    print('T-TEST Alert! We found significant differences in the new data based on T-test!')\n",
    "    print(significant_cols_df_ttest)\n",
    "\n",
    "if not significant_cols_df_ks.empty:\n",
    "    messagekstest = 'K-S TEST Alert! We found significant differences in the new data based on K-S test!'\n",
    "    print('K-S TEST Alert! We found significant differences in the new data based on K-S test!')\n",
    "    print(significant_cols_df_ks)\n",
    "else:\n",
    "    print(f\"No significant differences found at the specified {p_value_threshold} threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d536517f-608d-4763-bbc4-69e8ac3899e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data Exploration for Categorical Columns\n",
      "CHI^2 TEST\n",
      "New Data Exploration\n",
      "Alert! We found significant differences in the categorical features of the new data!\n",
      "                Feature       P-value\n",
      "0        market_segment  5.291329e-28\n",
      "1  distribution_channel  7.741914e-03\n",
      "2    reserved_room_type  2.246831e-09\n",
      "3    assigned_room_type  3.370485e-04\n",
      "4          deposit_type  1.099646e-06\n",
      "5         customer_type  3.131634e-05\n",
      "\n",
      "Distribution for market_segment BEFORE:\n",
      "Aviation         0.001917\n",
      "Complementary    0.006057\n",
      "Corporate        0.042945\n",
      "Direct           0.101812\n",
      "Groups           0.171536\n",
      "Offline TA/TO    0.207633\n",
      "Online TA        0.468101\n",
      "Name: market_segment, dtype: float64\n",
      "\n",
      "Distribution for market_segment AFTER:\n",
      "Direct       0.165775\n",
      "Online TA    0.834225\n",
      "Name: market_segment, dtype: float64\n",
      "\n",
      "Distribution for distribution_channel BEFORE:\n",
      "Corporate    0.054568\n",
      "Direct       0.119509\n",
      "GDS          0.001574\n",
      "TA/TO        0.824341\n",
      "Undefined    0.000009\n",
      "Name: distribution_channel, dtype: float64\n",
      "\n",
      "Distribution for distribution_channel AFTER:\n",
      "Direct    0.165775\n",
      "TA/TO     0.834225\n",
      "Name: distribution_channel, dtype: float64\n",
      "\n",
      "Distribution for reserved_room_type BEFORE:\n",
      "A    0.725492\n",
      "B    0.009670\n",
      "C    0.007270\n",
      "D    0.158357\n",
      "E    0.053170\n",
      "F    0.023860\n",
      "G    0.017046\n",
      "H    0.005081\n",
      "L    0.000053\n",
      "Name: reserved_room_type, dtype: float64\n",
      "\n",
      "Distribution for reserved_room_type AFTER:\n",
      "A    0.513369\n",
      "B    0.005348\n",
      "D    0.288770\n",
      "E    0.090909\n",
      "F    0.064171\n",
      "G    0.037433\n",
      "Name: reserved_room_type, dtype: float64\n",
      "\n",
      "Distribution for assigned_room_type BEFORE:\n",
      "A    0.625535\n",
      "B    0.018699\n",
      "C    0.019253\n",
      "D    0.209619\n",
      "E    0.063842\n",
      "F    0.030919\n",
      "G    0.020835\n",
      "H    0.005952\n",
      "I    0.003007\n",
      "K    0.002330\n",
      "L    0.000009\n",
      "Name: assigned_room_type, dtype: float64\n",
      "\n",
      "Distribution for assigned_room_type AFTER:\n",
      "A    0.491979\n",
      "B    0.005348\n",
      "D    0.304813\n",
      "E    0.090909\n",
      "F    0.064171\n",
      "G    0.037433\n",
      "K    0.005348\n",
      "Name: assigned_room_type, dtype: float64\n",
      "\n",
      "Distribution for deposit_type BEFORE:\n",
      "No Deposit    0.872008\n",
      "Non Refund    0.126603\n",
      "Refundable    0.001389\n",
      "Name: deposit_type, dtype: float64\n",
      "\n",
      "Distribution for deposit_type AFTER:\n",
      "No Deposit    1.0\n",
      "Name: deposit_type, dtype: float64\n",
      "\n",
      "Distribution for customer_type BEFORE:\n",
      "Contract           0.035192\n",
      "Group              0.004554\n",
      "Transient          0.744033\n",
      "Transient-Party    0.216222\n",
      "Name: customer_type, dtype: float64\n",
      "\n",
      "Distribution for customer_type AFTER:\n",
      "Group              0.005348\n",
      "Transient          0.893048\n",
      "Transient-Party    0.101604\n",
      "Name: customer_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('New Data Exploration for Categorical Columns')\n",
    "\n",
    "\n",
    "print('CHI^2 TEST')\n",
    "\n",
    "def chi2_test(cat_col, df1, df2):\n",
    "    # Calculate the frequency of each category in both dataframes\n",
    "    freq_df1 = df1[cat_col].value_counts().to_frame(name='count1')\n",
    "    freq_df2 = df2[cat_col].value_counts().to_frame(name='count2')\n",
    "    \n",
    "    # Merge the frequencies into a single dataframe\n",
    "    freq_df = freq_df1.merge(freq_df2, left_index=True, right_index=True, how='outer').fillna(0)\n",
    "    \n",
    "    # Perform the Chi-squared test\n",
    "    chi2_stat, p_val, dof, expected = stats.chi2_contingency(freq_df)\n",
    "    \n",
    "    return p_val\n",
    "\n",
    "# List of categorical columns to evaluate\n",
    "cat_col_eval = [\n",
    "    'meal', 'market_segment', 'distribution_channel', 'is_repeated_guest',\n",
    "    'reserved_room_type', 'assigned_room_type', 'deposit_type', 'customer_type'\n",
    "]\n",
    "\n",
    "print('New Data Exploration')\n",
    "\n",
    "# Initialize dictionary to store p-values\n",
    "p_values_cat = {}\n",
    "\n",
    "# Perform Chi-squared test on each categorical column\n",
    "for col in cat_col_eval:\n",
    "    p_val = chi2_test(col, hotel_bookings, data_profiling_before)\n",
    "    p_values_cat[col] = p_val\n",
    "\n",
    "# Filter columns with p-value less than the threshold\n",
    "significant_cats = {col: p for col, p in p_values_cat.items() if p < 0.01}\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "significant_data_cat = [(col, significant_cats[col]) for col in significant_cats]\n",
    "\n",
    "# Convert to DataFrame with columns for feature and p-value\n",
    "significant_cats_df = pd.DataFrame(significant_data_cat, columns=['Feature', 'P-value'])\n",
    "\n",
    "# Check if significant_cats_df is not empty and print\n",
    "if not significant_cats_df.empty:\n",
    "    print('Alert! We found significant differences in the categorical features of the new data!')\n",
    "    print(significant_cats_df)\n",
    "    \n",
    "    # For each significant feature, print the distribution before and after\n",
    "    for feature in significant_cats_df['Feature']:\n",
    "        print(f\"\\nDistribution for {feature} BEFORE:\")\n",
    "        print(hotel_bookings[feature].value_counts(normalize=True).sort_index())\n",
    "        \n",
    "        print(f\"\\nDistribution for {feature} AFTER:\")\n",
    "        print(data_profiling_before[feature].value_counts(normalize=True).sort_index())\n",
    "else:\n",
    "    print(f\"No significant differences in categorical features found at the specified 0.01 threshold.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
